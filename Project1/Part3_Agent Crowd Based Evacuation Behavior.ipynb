{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part 3: Agent Crowd Based Evacuation Behavior </h1>\n",
    "\n",
    "<h3>In this part, we modeled the boids evacuation behaviour using cellular automata. </h3>\n",
    "\n",
    "<h3>Conceptual Model: </h3>\n",
    "The particle’s movement probability grid is modified by the static and dynamic fields.\n",
    "The probability for each action is computed by:\n",
    "pij = NMijDijSij\n",
    "Dij is the modifier value from the dynamic field.\n",
    "Sij is the modifier value from the static field.\n",
    "N is a normalization factor to insure probabilities sum to 1.\n",
    "Note: Formula for pij does not have to be a simple product.\n",
    "Generalized as pij = N f(Mij, Dij, Sij).\n",
    "f(…) may include exponentials for different behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use(\"qt4agg\")\n",
    "import pylab as PL\n",
    "import random as RD\n",
    "import numpy as NP\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import distance as dist\n",
    "from Agent import Agent\n",
    "from math import sqrt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "RD.seed()\n",
    "\n",
    "populationSize = 64\n",
    "noiseLevel = 5\n",
    "avoidanceRadius = 50\n",
    "flockRadius = 100\n",
    "boardDimension = 1000\n",
    "\n",
    "#strengths are proportion of new weight vs proportion of old weight (0-1)\n",
    "avoidanceStrength = 0.8\n",
    "approachStrength = 0.5\n",
    "alignStrength = 0.3\n",
    "obstacleStrength = 1\n",
    "goalStrength = 1\n",
    "totalStrength = 0.1\n",
    "\n",
    "flag = [False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rules for Dynamic Field CA:</h3>\n",
    "If a pedestrian leaves a cell (x, y) the dynamic floor field Dxy corresponding to this cell is increased by ΔDxy.\n",
    "A virtual trace is left by the motion of pedestrians.\n",
    "A certain amount of the field is distributed among the neighboring cells to model diffusion.\n",
    "Diffusion is necessary because pedestrians do not necessarily follow exactly in the footsteps of others.\n",
    "The field strength is reduced by a decay constant δ to model decay of the field.\n",
    "Implies that the lifetime of the trace is finite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init1():\n",
    "    global time, agents, walls, goalPos\n",
    "\n",
    "    time = 0\n",
    "\n",
    "    scenario1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario 1: There is one exit for the agents to leave from, in the goal position (goalpos [500,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario1():\n",
    "    global agents, walls, goalPos, goals\n",
    "    agents = []\n",
    "    for i in range(populationSize):\n",
    "        row = i % 8\n",
    "        col = i / 8\n",
    "        newAgent = Agent(row*50+300, col*50+300, RD.gauss(0, noiseLevel), RD.gauss(0, noiseLevel), 0, 0)\n",
    "        agents.append(newAgent)\n",
    "        \n",
    "    walls = []\n",
    "    for i in range(60):\n",
    "        newWall = [i*5+100, 100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(61):\n",
    "        newWall = [i*5+600, 100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(160):\n",
    "        newWall = [i*5+100, 900]\n",
    "        walls.append(newWall)\n",
    "    for i in range(160):\n",
    "        newWall = [100, i*5+100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(160):\n",
    "        newWall = [900, i*5+100]\n",
    "        walls.append(newWall)\n",
    "        \n",
    "    goals = 1\n",
    "    goalPos = [500,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    PL.cla()\n",
    "    PL.plot([wall[0] for wall in walls], [wall[1] for wall in walls], 'ro')\n",
    "    x = [ag.posX for ag in agents]\n",
    "    y = [ag.posY for ag in agents]\n",
    "    PL.plot(x, y, 'bo')\n",
    "    \n",
    "    PL.axis('scaled')\n",
    "    PL.axis([0, boardDimension, 0, boardDimension])\n",
    "    PL.title('t = ' + str(time))\n",
    "    PL.pause(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step function updates positions of each boid every time step and changes their respective velocities. Once each boid agent has reached the target they will 'escape', which is the escape function and will be effectively removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step():\n",
    "    \"\"\"Update positions of each agent each time step\"\"\"\n",
    "    global time, agents, walls, goalPos, flag\n",
    "\n",
    "    time += 1\n",
    "    \n",
    "    for ag in agents:\n",
    "        colVect = ag.collisions(ag, avoidanceRadius, agents)\n",
    "        avgLoc, avgVel = ag.getFlock(agents, flockRadius)\n",
    "        alignVect = ag.align(avgVel, populationSize)\n",
    "        apprVect = ag.approach(avgLoc)\n",
    "        avoidVect = ag.avoidObstacles(walls, avoidanceRadius, flag)\n",
    "        goalVect = ag.goal(goalPos)\n",
    "\n",
    "        \n",
    "        # Limit the max velocity \n",
    "        limit = 50\n",
    "        if ag.oldVelX > limit:\n",
    "            ag.oldVelX = sqrt(ag.oldVelX - limit) + 0.8 * limit\n",
    "        if ag.oldVelY > limit:\n",
    "            ag.oldVelY = sqrt(ag.oldVelY - limit) + 0.8 * limit\n",
    "        \n",
    "        # If there are multiple exits, agents should move to the closest one\n",
    "        if goals == 2:\n",
    "            d1 = dist.euclidean([ag.posX, ag.posY], goalPos)\n",
    "            d2 = dist.euclidean([ag.posX, ag.posY], goalPos2)\n",
    "            if d1 < d2:\n",
    "                goalVect = ag.goal(goalPos)\n",
    "            else:\n",
    "                goalVect = ag.goal(goalPos2)\n",
    "            escape(goalPos2)\n",
    "        escape(goalPos)\n",
    "        \n",
    "        weightTot = avoidanceStrength + alignStrength + approachStrength + obstacleStrength + goalStrength\n",
    "        weights = [avoidanceStrength / weightTot, alignStrength / weightTot, approachStrength / weightTot, obstacleStrength / weightTot, goalStrength / weightTot]\n",
    "            \n",
    "        ag.newVelX = (1 - totalStrength) * ag.oldVelX + totalStrength * (colVect[0] * weights[0] + alignVect[0] * weights[1] + apprVect[0] * weights[2] + avoidVect[0] * weights[3] + goalVect[0] * weights[4])       \n",
    "        ag.newVelY = (1 - totalStrength) * ag.oldVelY + totalStrength * (colVect[1] * weights[0] + alignVect[1] * weights[1] + apprVect[1] * weights[2] + avoidVect[1] * weights[3] + goalVect[1] * weights[4])\n",
    "        \n",
    "        # Update positions using new velocities\n",
    "        # Last number changes speed on screen\n",
    "        ag.posX += ag.newVelX * 0.1\n",
    "        ag.posY += ag.newVelY * 0.1\n",
    "        \n",
    "        # Wraps agents around when they leave the screen\n",
    "        # And shifts new weights to old weight position\n",
    "        for ag in agents:\n",
    "            ag.posX = ag.posX % boardDimension\n",
    "            ag.posY = ag.posY % boardDimension\n",
    "            ag.oldVelX = ag.newVelX\n",
    "            ag.oldVelY = ag.newVelY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Escape method removes the agents when they leave successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape(goalPos):\n",
    "    global agents\n",
    "    for ag in agents:\n",
    "        if ag.posX < 100 or ag.posX > 900 or ag.posY < 100 or ag.posY > 900:\n",
    "            agents.remove(ag)\n",
    "    \n",
    "\n",
    "def normalize(x, y):\n",
    "    mag = float(NP.sqrt(x*x + y*y))\n",
    "    newX = x/mag\n",
    "    newY = y/mag\n",
    "    return [newX, newY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scenario 2:</h3> There are two exits for the agents to leave from\n",
    "1. ) in the goal position (goalpos [500,100])\n",
    "2. ) in the goal position 2 (goalpos2 [500,900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario2():\n",
    "    global agents, walls, goalPos, goalPos2, goals\n",
    "    agents = []\n",
    "    for i in range(populationSize):\n",
    "        row = i % 8.0\n",
    "        col = i / 8.0\n",
    "        newAgent = Agent(row*50+300, col*50+300, RD.gauss(0, noiseLevel), RD.gauss(0, noiseLevel), 0, 0)\n",
    "        agents.append(newAgent)\n",
    "        \n",
    "    walls = []\n",
    "    for i in range(60):\n",
    "        newWall = [i*5+100, 100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(61):\n",
    "        newWall = [i*5+600, 100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(60):\n",
    "        newWall = [i*5+100, 900]\n",
    "        walls.append(newWall)\n",
    "    for i in range(61):\n",
    "        newWall = [i*5+600, 900]\n",
    "        walls.append(newWall)\n",
    "    for i in range(160):\n",
    "        newWall = [100, i*5+100]\n",
    "        walls.append(newWall)\n",
    "    for i in range(160):\n",
    "        newWall = [900, i*5+100]\n",
    "        walls.append(newWall)\n",
    "        \n",
    "    goals = 2\n",
    "    goalPos = [500, 100]\n",
    "    goalPos2 = [500, 900]\n",
    "    \n",
    "def init2():\n",
    "    global time, agents, walls, goalPos\n",
    "\n",
    "    time = 0\n",
    "\n",
    "    scenario2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Run A Scenario</h3>\n",
    "itit1() will run scenario 1. To run scenario 2, change to init2()\n",
    "\n",
    "Notice that the time it takes each frame to load increases as the program runs, this is because the 'lag' is caused by all of the calculations that are being done in real time so when there are less agents, there are less calculations to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init1()\n",
    "while(True):\n",
    "    clear_output(wait=True)\n",
    "    draw()\n",
    "    step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
